{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e43a453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n",
      "4.5.2\n",
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import functools\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tfds.__version__)\n",
    "print(hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b5d7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 00:41:16.643004: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 1.45 GiB (download: 1.45 GiB, generated: 1.46 GiB, total: 2.91 GiB) to /home/jangedoo/tensorflow_datasets/imagenette/full-size-v2/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2726f01dda14117a919243373407a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cea5651309b45bab1ab4ceaee4f343d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fdc190f6cc4496b172e06cacea837d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/9469 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jangedoo/tensorflow_datasets/imagenette/full-size-v2/1.0.0.incompleteDEV618/imagenette-train.t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation examples...:   0%|          | 0/3925 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling /home/jangedoo/tensorflow_datasets/imagenette/full-size-v2/1.0.0.incompleteDEV618/imagenette-validat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imagenette downloaded and prepared to /home/jangedoo/tensorflow_datasets/imagenette/full-size-v2/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 00:44:58.509101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-30 00:44:58.509581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-30 00:44:58.510105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-30 00:44:58.510753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-30 00:44:58.510767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-03-30 00:44:58.511118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-03-30 00:44:58.511142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5932 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "ds = tfds.load(\"imagenette\")\n",
    "def extract_image(example):\n",
    "    image = example['image']\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image, height, width):\n",
    "    image = tf.image.resize_with_crop_or_pad(image, target_height=height, target_width=width)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_image_batches(batch_size=128, height=256, width=256):\n",
    "    partial_preprocess_image = functools.partial(preprocess_image, height=height, width=width)\n",
    "    train_ds = ds['train']\n",
    "    train_ds = ( train_ds.map(extract_image)\n",
    "                .map(partial_preprocess_image)\n",
    "                .cache()\n",
    "                .shuffle(buffer_size=1000)\n",
    "                .batch(batch_size)\n",
    "                .prefetch(tf.data.AUTOTUNE)\n",
    "                )\n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b9f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = IMG_HEIGHT = 256\n",
    "train_ds = get_image_batches(batch_size=BATCH_SIZE, height=IMG_HEIGHT, width=IMG_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6411f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 00:44:59.336200: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-30 00:44:59.805480: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 23970816 exceeds 10% of free system memory.\n",
      "2022-03-30 00:44:59.808980: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 31166226 exceeds 10% of free system memory.\n",
      "2022-03-30 00:45:00.537543: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 25165824 exceeds 10% of free system memory.\n",
      "2022-03-30 00:45:00.570503: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 25165824 exceeds 10% of free system memory.\n",
      "2022-03-30 00:45:00.601760: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 25165824 exceeds 10% of free system memory.\n",
      "2022-03-30 00:45:01.294674: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "images = np.array([img for batch in train_ds.take(20) for img in batch]) # take 20 batches \n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774dd98a",
   "metadata": {},
   "source": [
    "# Vectorization\n",
    "\n",
    "- load model\n",
    "- extract features using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0045884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/5\", trainable=False)\n",
    "])\n",
    "vectorizer.build([None, IMG_HEIGHT, IMG_WIDTH, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fe300fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-30 00:45:32.263662: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-03-30 00:45:32.770635: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 1536)\n"
     ]
    }
   ],
   "source": [
    "features = vectorizer.predict(images, batch_size=BATCH_SIZE)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e184af1",
   "metadata": {},
   "source": [
    "# Image search using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "076f4a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(metric='cosine')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=5, metric=\"cosine\")\n",
    "knn.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9a53c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163d111784cb4336821cfd14f7eb80a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='image_idx', max=639), IntSlider…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_similar_images(image_idx, n_neighbors=10):\n",
    "    input_images = images[image_idx:image_idx+5]\n",
    "    features = vectorizer.predict(input_images)\n",
    "    knn_output = knn.kneighbors(features, n_neighbors=n_neighbors)\n",
    "    \n",
    "    images_with_distances_and_nbors = zip(input_images, *knn_output)\n",
    "    \n",
    "    fig, axes = plt.subplots(len(input_images), n_neighbors+1, figsize=(20, len(input_images)*3))\n",
    "    \n",
    "    for i, (image, distances, nbors) in enumerate(images_with_distances_and_nbors):\n",
    "        for j in range(n_neighbors+1):\n",
    "            ax = axes[i, j]\n",
    "            img = image if j==0 else images[nbors[j-1]]\n",
    "            if j == 0:\n",
    "                ax.set_title(\"Input Image\")\n",
    "            else:\n",
    "                ax.set_title(f\"Sim: {1-distances[j-1]:.2f}\")\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(img)\n",
    "\n",
    "import ipywidgets as w\n",
    "_ = w.interact(show_similar_images, \n",
    "    image_idx=w.IntSlider(max=len(images)-1, continuous_update=False),\n",
    "    n_neighbors=w.IntSlider(min=2, value=5, max=10, continuous_update=False),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
